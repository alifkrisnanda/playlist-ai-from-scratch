{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Import dataset\n"
      ],
      "metadata": {
        "id": "sLbSnYypZDV6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install mnist"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SxJW1O8CZFD0",
        "outputId": "ea0d1425-7960-4bfe-8f19-e700a73e5047"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting mnist\n",
            "  Downloading mnist-0.2.2-py2.py3-none-any.whl (3.5 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from mnist) (1.23.5)\n",
            "Installing collected packages: mnist\n",
            "Successfully installed mnist-0.2.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import mnist"
      ],
      "metadata": {
        "id": "-r4qW1JGZIRQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data preparation\n"
      ],
      "metadata": {
        "id": "X-Fgx3zLZOhm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#digunakan untuk reshape array gambar.\n",
        "def reshapeImages(images):\n",
        "    images = images.reshape(images.shape[0], -1)\n",
        "    return images\n",
        "\n",
        "#digunakan oleh reshapeImages untuk mereshape data train dan test dari dataset\n",
        "def reshapedMnistData(train_images, train_labels, test_images, test_labels):\n",
        "    train_images = reshapeImages(train_images)\n",
        "    train_labels = reshapeImages(train_labels)\n",
        "    test_images = reshapeImages(test_images)\n",
        "    test_labels = reshapeImages(test_labels)\n",
        "    return train_images, train_labels, test_images, test_labels\n",
        "\n",
        "#fungsi ini memuat dataset mnist\n",
        "def getMnistData(reshaped=True):\n",
        "    train_images = mnist.train_images()\n",
        "    train_labels = mnist.train_labels()\n",
        "    test_images = mnist.test_images()\n",
        "    test_labels = mnist.test_labels()\n",
        "    if reshaped == True:\n",
        "        return reshapedMnistData(train_images, train_labels, test_images, test_labels)\n",
        "    else:\n",
        "        return train_images, train_labels, test_images, test_labels\n"
      ],
      "metadata": {
        "id": "yzCqVvieZREJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Conv"
      ],
      "metadata": {
        "id": "txcU4v8SZXVp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Conv(object):\n",
        "\n",
        "#konstruktor kelas inisiasi inisiasi objek conv dengan jumlah filter\n",
        "    def __init__(self, num_filters):\n",
        "        self.num_filters = num_filters\n",
        "        self.filters = np.random.randn(num_filters, 3, 3, ) / 9\n",
        "\n",
        "#untuk mengiterasi melalui semua region 3x3 di dalam gambar.\n",
        "#region ini digunakan untuk menghitung hasil konvolusi\n",
        "    def iterate_regions(self, image):\n",
        "        h, w = image.shape\n",
        "        for i in range(h - 2):\n",
        "            for j in range(w - 2):\n",
        "                im_region = image[i:i+3, j:j+3]\n",
        "                yield im_region, i, j\n",
        "\n",
        "#melakukan proses konvolusi pada input.\n",
        "#matriks input diiterasi melalui semua region 3x3 menggunakan iterate_region\n",
        "    def forward(self, input):\n",
        "        self.last_input = input\n",
        "        h, w = input.shape\n",
        "        output = np.zeros(shape=(h-2, w-2, self.num_filters))\n",
        "        for im_region, i, j in self.iterate_regions(input):\n",
        "            output[i, j] = np.sum(im_region * self.filters, axis=(1, 2))\n",
        "        return output\n",
        "\n",
        "# Metode ini mengimplementasikan proses backpropagation untuk layer konvolusi.\n",
        "#Menghitung gradien dari loss terhadap filter menggunakan chain rule, dan kemudian memperbarui filter dengan gradien tersebut.\n",
        "#dL_dout = loss gradient\n",
        "    def backprop(self, dL_dout, learning_rate):\n",
        "        dL_dfilters = np.zeros(self.filters.shape)\n",
        "        for im_region, i, j in self.iterate_regions(self.last_input):\n",
        "            for f in range(self.num_filters):\n",
        "                dL_dfilters[f] += dL_dout[i, j, f] * im_region\n",
        "\n",
        "\n",
        "        self.filters -= learning_rate * dL_dfilters\n",
        "        return None"
      ],
      "metadata": {
        "id": "HWz4kvkjZWL0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "max pool"
      ],
      "metadata": {
        "id": "Bsm2qcSlZhWR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MaxPool(object):\n",
        "\n",
        "# Metode ini digunakan untuk mengiterasi melalui semua region 2x2\n",
        "    def iterate_regions(self, image):\n",
        "        h, w, _ = image.shape\n",
        "\n",
        "        new_h = h // 2\n",
        "        new_w = w // 2\n",
        "\n",
        "        for i in range(new_h):\n",
        "            for j in range(new_w):\n",
        "                im_region = image[(i*2):(i*2 + 2), (j*2):(j * 2 + 2)]\n",
        "                yield im_region, i, j\n",
        "\n",
        "# melakukan proses max pooling pada input. Matriks input diiterasi melalui semua region 2x2 menggunakan iterate region\n",
        "    def forward(self, input):\n",
        "        self.last_input = input\n",
        "        h, w, num_filters = input.shape\n",
        "        output = np.zeros(shape=(h // 2, w // 2, num_filters))\n",
        "        for im_region, i, j in self.iterate_regions(input):\n",
        "            output[i, j] = np.amax(im_region, axis=(0, 1))\n",
        "        return output\n",
        "\n",
        "# metode ini mengimplementasikan proses backpropagation untuk layer max pooling.\n",
        "# return gradien loss\n",
        "    def backprop(self, dL_dout):\n",
        "        dL_dinput = np.zeros(shape=self.last_input.shape)\n",
        "        for im_region, i, j in self.iterate_regions(self.last_input):\n",
        "            h, w, f = im_region.shape\n",
        "            amax = np.amax(im_region, axis=(0, 1))\n",
        "            for i2 in range(h):\n",
        "                for j2 in range(w):\n",
        "                    for f2 in range(f):\n",
        "                        if im_region[i2, j2, f2] == amax[f2]:\n",
        "                            dL_dinput[i*2 + i2, j*2 + j2,\n",
        "                                      f2] = dL_dout[i, j, f2]\n",
        "        return dL_dinput"
      ],
      "metadata": {
        "id": "8XOKN4VLZj-4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "soft max"
      ],
      "metadata": {
        "id": "pYPQpB67Zq85"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Softmax:\n",
        "# inisialisasi objek Softmax dengan menghasilkan bobot (weights) secara acak dan menginisialisasi bias dengan nilai nol.\n",
        "    def __init__(self, input_len, nodes):\n",
        "        self.weights = np.random.randn(input_len, nodes) / input_len\n",
        "        self.biases = np.zeros(shape=nodes)\n",
        "\n",
        "# roses feedforward pada layer Softmax. Input di-flatten menjadi vektor satu dimensi,\n",
        "# kemudian dihitung totalnya dengan mengalikan dengan bobot (weights), menambahkan bias, dan kemudian diaplikasikan fungsi softmax.\n",
        "    def forward(self, input):\n",
        "        self.last_input_shape = input.shape\n",
        "        input = input.flatten()\n",
        "        self.last_input = input\n",
        "        totals = np.dot(input, self.weights) + self.biases\n",
        "        self.last_totals = totals\n",
        "        exp = np.exp(totals)\n",
        "        return exp / np.sum(exp, axis=0)\n",
        "\n",
        "# mengimplementasikan proses backpropagation untuk layer Softmax.\n",
        "# menghitung gradien loss terhadap input, bobot, dan bias\n",
        "    def backprop(self, dL_dout, learning_rate):\n",
        "\n",
        "        for i, gradient in enumerate(dL_dout):\n",
        "            if gradient == 0:\n",
        "                continue\n",
        "            # e^totals\n",
        "            t_exp = np.exp(self.last_totals)\n",
        "\n",
        "            # sum dari semua e^totals\n",
        "            S = np.sum(t_exp)\n",
        "\n",
        "            # gradients output[i] dari total totals\n",
        "            dout_dt = -t_exp[i] * t_exp / S**2\n",
        "\n",
        "            # dout = turunan output class\n",
        "            dout_dt[i] = t_exp[i] * (S - t_exp[i]) / S**2\n",
        "\n",
        "            # gradien total untuk weight, bias, input\n",
        "            dt_dw = self.last_input\n",
        "            dt_db = 1\n",
        "            dt_dinputs = self.weights\n",
        "\n",
        "            # loss gradient untuk total\n",
        "            dL_dt = gradient * dout_dt\n",
        "\n",
        "            # loss gradient untuk weight, bias, input\n",
        "            dL_dw = dt_dw[np.newaxis].T @ dL_dt[np.newaxis]\n",
        "            dL_db = dL_dt * dt_db\n",
        "            dL_dinputs = dt_dinputs @ dL_dt\n",
        "\n",
        "            # update weight dan bias\n",
        "            self.weights -= learning_rate * dL_dw\n",
        "            self.biases -= learning_rate * dL_db\n",
        "\n",
        "            return dL_dinputs.reshape(self.last_input_shape)\n"
      ],
      "metadata": {
        "id": "losGoE6lZsf0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train dataset"
      ],
      "metadata": {
        "id": "gOEP0KNWZyES"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_images, train_labels, test_images, test_labels = getMnistData(\n",
        "    reshaped=False)\n",
        "train_images = train_images[:500]\n",
        "train_labels = train_labels[:500]\n",
        "test_images = test_images[:200]\n",
        "test_labels = test_labels[:200]\n",
        "\n",
        "conv_layer = Conv(num_filters=8)       # 28x28x1 => 26x26x8\n",
        "pooling_layer = MaxPool()                # 26x26x8 => 13x13x8\n",
        "softmax_layer = Softmax(13*13*8, 10)      # 13x13x8 => 10\n",
        "\n",
        "\n",
        "def forward(image, label):\n",
        "    # konversi image [0, 255] => [-0.5, 0.5]\n",
        "    out = conv_layer.forward((image / 255) - 0.5)\n",
        "    out = pooling_layer.forward(out)\n",
        "    out = softmax_layer.forward(out)\n",
        "\n",
        "    loss = -np.log(out[label])\n",
        "    acc = 1 if np.argmax(out) == label else 0\n",
        "    return out, loss, acc\n",
        "\n",
        "\n",
        "def train(im, label, lr=.005):\n",
        "    # forward\n",
        "    out, loss, acc = forward(im, label)\n",
        "    # gradient awal\n",
        "    gradient = np.zeros(10)\n",
        "    gradient[label] = -1 / out[label]\n",
        "    # backprop\n",
        "    gradient = softmax_layer.backprop(gradient, lr)\n",
        "    gradient = pooling_layer.backprop(gradient)\n",
        "    conv_layer.backprop(gradient, lr)\n",
        "\n",
        "    return loss, acc\n",
        "\n",
        "\n",
        "print('MNIST CNN from Scratch')\n",
        "epochs = 5\n",
        "\n",
        "# Training\n",
        "for epoch in range(epochs):\n",
        "    print(f\"-------Epoch {epoch+1}-------\")\n",
        "    # mengacak data train\n",
        "    permutation = np.random.permutation(len(train_images))\n",
        "    train_images = train_images[permutation]\n",
        "    train_labels = train_labels[permutation]\n",
        "\n",
        "    # Train\n",
        "    loss = 0\n",
        "    num_correct = 0\n",
        "    for i, (im, label) in enumerate(zip(train_images, train_labels)):\n",
        "        if i > 0 and i % 200 == 99:\n",
        "            print(\n",
        "                f'[langkah {i}] 200 langkah terakhir: rata-rata loss {loss/100:.3f} | akurasi: {num_correct}')\n",
        "\n",
        "            loss = 0\n",
        "            num_correct = 0\n",
        "\n",
        "        l, acc = train(im, label)\n",
        "        loss += l\n",
        "        num_correct += acc"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UooOaNAXZxA8",
        "outputId": "badd8e5e-cc19-4066-e605-a764217b254f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MNIST CNN from Scratch\n",
            "-------Epoch 1-------\n",
            "[langkah 99] 200 langkah terakhir: rata-rata loss 2.248 | akurasi: 19\n",
            "[langkah 299] 200 langkah terakhir: rata-rata loss 3.728 | akurasi: 89\n",
            "[langkah 499] 200 langkah terakhir: rata-rata loss 1.975 | akurasi: 145\n",
            "-------Epoch 2-------\n",
            "[langkah 99] 200 langkah terakhir: rata-rata loss 0.681 | akurasi: 78\n",
            "[langkah 299] 200 langkah terakhir: rata-rata loss 1.203 | akurasi: 161\n",
            "[langkah 499] 200 langkah terakhir: rata-rata loss 1.209 | akurasi: 163\n",
            "-------Epoch 3-------\n",
            "[langkah 99] 200 langkah terakhir: rata-rata loss 0.503 | akurasi: 82\n",
            "[langkah 299] 200 langkah terakhir: rata-rata loss 0.785 | akurasi: 178\n",
            "[langkah 499] 200 langkah terakhir: rata-rata loss 0.992 | akurasi: 167\n",
            "-------Epoch 4-------\n",
            "[langkah 99] 200 langkah terakhir: rata-rata loss 0.298 | akurasi: 90\n",
            "[langkah 299] 200 langkah terakhir: rata-rata loss 0.699 | akurasi: 178\n",
            "[langkah 499] 200 langkah terakhir: rata-rata loss 0.885 | akurasi: 174\n",
            "-------Epoch 5-------\n",
            "[langkah 99] 200 langkah terakhir: rata-rata loss 0.276 | akurasi: 91\n",
            "[langkah 299] 200 langkah terakhir: rata-rata loss 0.565 | akurasi: 184\n",
            "[langkah 499] 200 langkah terakhir: rata-rata loss 0.644 | akurasi: 182\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Test"
      ],
      "metadata": {
        "id": "MX5PbjsOaQVz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Testing the network\n",
        "print('\\n--- Test CNN ---')\n",
        "\n",
        "loss = 0\n",
        "num_correct = 0\n",
        "for im, label in zip(test_images, test_labels):\n",
        "    _, l, acc = forward(im, label)\n",
        "    loss += l\n",
        "    num_correct += acc\n",
        "\n",
        "num_test = len(test_labels)\n",
        "print(f'tes loss: {loss / num_test}')\n",
        "print(f'tes akurasi: {num_correct / num_test}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nBSQYjz6aU76",
        "outputId": "343f0f1c-c24d-499b-9ee8-583c84da52b3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Test CNN ---\n",
            "tes loss: 0.6155041187261642\n",
            "tes akurasi: 0.78\n"
          ]
        }
      ]
    }
  ]
}